{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kV9SWKZSWAh0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "#from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pADt5CykCKaz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labeliser_tweet(df, nb_tweets=5, random_state=0):\n",
    "    \n",
    "    # V√©rifier si le fichier \"label.csv\" existe et charger les tweet_id d√©j√† labelis√©s\n",
    "    tweets_labelises = set()\n",
    "    try:\n",
    "        with open('label.csv', mode='r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                tweets_labelises.add(row['tweet_id'])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    # S√©lectionner un √©chantillon al√©atoire de tweets non encore labelis√©s\n",
    "    df_a_labeliser = df[~df.index.isin(tweets_labelises)].sample(n=nb_tweets, random_state=random_state)\n",
    "    \n",
    "    # Labeliser les tweets s√©lectionn√©s et enregistrer les labels dans un fichier CSV\n",
    "    with open('label.csv', mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if f.tell() == 0:\n",
    "            writer.writerow(['tweet_id', 'text', 'label'])\n",
    "        for tweet_id, text in df_a_labeliser['text'].items():\n",
    "            label = input(f'Label pour le tweet suivant :\\n{text}\\n')\n",
    "            # √âcrire les donn√©es labelis√©es dans le fichier CSV\n",
    "            writer.writerow([tweet_id, text, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "fGUP7YlcanuW",
    "outputId": "9d6da307-a96e-45dc-ca7f-acd015856f90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_concat_clean/base_annotation_fev23.csv', index_col='tweet_id').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKjOXzht-kvr",
    "outputId": "18bd519c-92df-4ce6-c15c-ec4555f02a8c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label pour le tweet suivant :\n",
      "Homme femelle N¬∞19: ü§≥\"Fais tr√®s vite mon amour, car tu dois ensuite aller lui les torcher... Ta ch√©rie qui t'aime\".  #feminisme #metoo #violencesconjugales https://t.co/wEyZ2ucc0c\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Proc√®s de #balancetonporc : Sandra Muller d√©nonce ‚Äúune inversion des r√¥les o√π le pr√©dateur devient la proie, la proie devient le pr√©dateur\"  ‚û° https://t.co/tXIFSsR12K https://t.co/law5XfRHTz\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@canalplus, une r√©action officielle peut-√™tre sur les r√©v√©lations visant @PierreMenes ?... #PierreMenesOut #balancetonporc   #BalanceTonMenes #JeNeSuisPasUneSalope https://t.co/ParThES1UG\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "‚ÄúJ‚Äôai pouss√© un cri de col√®re‚Äù : jug√©e en diffamation, la journaliste Sandra Muller √† l‚Äôorigine de #Balancetonporc plaide ‚Äúla lib√©ration de la parole des femmes‚Äù https://t.co/nHix95DBmq\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "https://t.co/wFK3baer5V ‚Ä¶ dossier sur anissa jbr (achat de follower ,consomation de stup escorting) #jeremstarcensure   #BalanceTonPorc   #jeremstarcensure #babybel    #LaVilla3 #fiansosurskyrock  #JeremstarGate  #BALANCETONBABYBEL  #BalanceTonPorc  #Balancetatruie  #LPEPDLA\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@RC_ML pour continuer sur la vague de ce matin, la merveilleuse Nadia Daam @zappette parle, elle aussi, de son scepticisme de voir Mme Deneuve dans le m√©tro √† 8h du mat. #moiaussi #MeToo #BalanceTonPorc https://t.co/Ns8vVKXAS0 :QT: \"Les am√©ricains ont Oprah Winfrey et des d√©bats sur Woody Allen, nous on a Elisabeth L√©vy, des d√©fenseurs du droit inali√©nable √† coller des mains au cul, et des d√©bats sur les blagues de Tex !\"  R√©√©coutez le billet de Nadia Daam (@Zappette) #E1matin ‚¨áÔ∏è https://t.co/92svLYh4Vj\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@sychazot Et comme elle ne va pas √™tre nomm√©e elle va encore instrumentaliser #metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@TPZ_Rap ... elle d√©nonce des choses ce qui a un lien avec le #balancetonporc ... la comparaison est pas n√©cessaire bref\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "On se demandera aussi si celles qui ont us√© de leurs atouts via promotion canap√© pour un poste parleront..#balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "√ßa critique Pierre M√®nes mais √ßa klaxonne, siffle et traite les femmes quand √ßa passe en bande dans une Peugeot 206 üíÄüíÄüíÄ #PierreMenesOut #TPMP #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@SDJ_LCP a vot√© suite √† la direction de remettre @frhaz √† l'antenne .. √©trangement √ßa ne choque pas beaucoup de monde .. c'est fini #Balancetonporc ? O√π √ßa vaut que pour certains #Haziza https://t.co/EOFckFfNbp\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Plaintes pour violences sexuelles (par le dessinateur Schvartz) -&gt; https://t.co/ymSfoZ7Wok #actualit√©endessins #JM #LOL #violencessexuelles #agressionssexuelles #violencesfaitesauxfemmes #harc√®lementsexuel #paroledesfemmes #balanceTonPorc #schvartz #weinsteinscandal\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#Gis√®leHalimi √©tait heureuse de voir qu'il y avait des ferments de r√©volte un peu partout   Exemple : #MeToo  Annick Cojean  Cl√©a @Zenon8703 https://t.co/z3svClWRO6\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Vous pouvez √©galement le faire au commissariat ou gendarmerie le/la plus proche de chez vous #balancetonporc https://t.co/qWsG8KMISx\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Erdoƒüan le Dictateur islamiste !!! Insulte et amalgame volontaire avec des groupuscules terroristes. Erdoƒüan les combats depuis des lustres alors que les pr√©c√©dents les caressaient dans le sens du poil sans aucun gain !  #BalanceTonPastƒ±rma (contre attaque √† #BalanceTonPorc)\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Un peu d'humour #balancetonporc üòÇ https://t.co/eL4JX56m0f\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@FanJeanDujardin C bizarre de revoir #OSS117 au Br√©sil et ses r√©pliques sexistes qq mois apr√®s #BalanceTonPorc .. Mais l'humour a tjs raison\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#BalanceTonPorc Squeezie avait donc raison\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@raphpradeau L'essentiel est qu'on laisse dans l'opacit√© le #MobbingEducationNationale et les violences sexuelles commises par des principaux et des proviseurs.  #metoo #moiaussi   #PasDeVague #OmertaEducatioNationale  https://t.co/ffGjK9kDQM\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#MeToo  √Ä celui qui m'a embrass√© et frapp√©.\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Regardez le point de vue de @grosfilley et l'interview d'Anne Morelli, l'une des signataires de la tribune publi√©e hier dans Le Monde qui d√©nonce un certain f√©minisme qui exprimerait \"une certaine haine des hommes\" https://t.co/hxjPAAQ43T #Jour1 #MeToo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "RT @hrw au sujet du mouvement #MeToo en #Iran, o√π des voix s'√©l√®vent pour demander une loi + forte concernant les violences contre les #femmes. https://t.co/W3yVudkzJq\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Ta copine de bac √† sable t'a vol√© ta pelle quand t'avais 3 ans? Ta voisine de classe t'a pas laiss√© copier sur sa dict√©e? Ta copine t'a quitt√© alors que vous vous √©tiez promis l'amour √©ternel √† 14 ans? D√©foule toi sur #Balancetapouffe OSEF. Les vrais pb sont l√† -&gt; #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Ce que #metoo a chang√© pour les journalistes https://t.co/j1bwq1bcz9\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#MetooAmnesie  #metooinceste  Tu aimes ton metier, tu es oblig√© de t arr√™ter + de 3 mois car tu as peur, naus√©e, oppression, panique, flash, non-reconnaissance des gens en crises, concentration faible Et que ce n est pas de TA FAUTE! C est insupportable! SVP, Qui est concern√© ?\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le chef du bureau de liaison d‚ÄôIsra√´l au Maroc d√©ment les accusations d‚Äôabus sexuels #metoo https://t.co/TFeRW5lOPH\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "M√™me Habill√© Avec Une Tunique XXL, Le Pervers Cherchera Toujours A Mater. #BalanceTonPorc\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Ensemble, sortons du silence ! Appelez d√®s maintenant le 0805 802 804 ou le 0800 100 811 depuis l'outre-mer du lundi au vendredi de 10h √† 19h. T√©moignez pour vous. T√©moigner pour les enfants victimes. T√©moignez, tout simplement. @CIIVISE_contact  #Metooinceste #ViolenceSexuelles https://t.co/NoJky5WvM4\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Grande diff√©rence toutefois dans cette √©dition 2018, qui √©tait davantage plac√©e sous le slogan #MeToo, plut√¥t que #ResistTrump. https://t.co/9aSHEs85xZ\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Via @euronewsfr : Le producteur Harvey Weinstein exclu de l'Acad√©mie des Oscars https://t.co/WRV4LYbazT =C‚Äôest tout ?#balancetonporc\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@AlexDevecchio @PascalPraud le bin√¥me inf√¢me. 2 ideologues d‚Äôextreme droite raciste islamophobe. Pas content que ‚Äòles femmes fran√ßaises musulmanes n‚Äôaient pas utilis√© le hashtag #balancetonporc ‚Äò car elles auraient peur de se faire √©gorg√©s: ils sont journalistes, jamais inqui√®t√©s https://t.co/C5DtnSXJBb :QT: üî¥üá´üá∑#FRANCE : Mensonges d'@AlexDevecchio (journaliste au #Figaro) qui dit, je cite \"elles se font √©gorg√©es en bas de leurs cit√©s\".üßê #Mytho https://t.co/ORqkILKwn8\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#MeToo lib√®re la parole en #Egypte o√π le harc√®lement sexuel reste encore tabou, explique le #NobelAlternatif @Mozn https://t.co/lgdzteIrhU\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc  #balancetonporc qu'elle ambiance quand les hommes ne feront que r√™ver au bon vieux temps...\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc s'habiller en jean basket ds ton village car du + jeune au +++ √¢g√© tu es un morceau de viande!!! √Ä vomir!\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "@TheDracerGx et m√™me d‚Äôun buddy movie avec Samuel L. Jackson, sur fond de revendications f√©ministes pour marquer un peu plus Hollywood dans l‚Äô√®re #MeToo.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "On ne voit plus jm maire #tpmp petit probl√®me avec #balancetonporc?\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Chrronique de @sophiedurocher qui pisse sur le cadavre encore chaud d‚Äôun p√®re de 3 enfants.   Sophie veut surtout pas qu‚Äôon oublie #metoo dans le cas de Kobe mais elle est beaucoup plus silencieuse sur la cas de l‚Äôami Rozon. Les vacances √† Paris √ßa forge des liens solides. https://t.co/gTXYYtqhR1\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#YoutubeusesDay ! Bravo mesdames !!! Svp (et je m'adresse aux femmes un minimum intelligentes). Vs v√©hiculez une influence sur les jeunes. Pourriez vs faire de la pr√©vention contre la #pedocriminalite dans vos vid√©os/reseaux ? @innocencedanger #iwas   https://t.co/1PkpS3jKLJ\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label pour le tweet suivant :\n",
      "celles et ceux qui tweetent sur le #Iwas vous √™tes tlmt fort sachez le, vous m√©ritez d‚Äô√™tre entendus\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Excellente analyse sur le tr√®s entendu \"#MeToo c'est bien, mais...\" https://t.co/tQvyCQX4wu\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Je rentre dans un magazin le gerant me suit \"pour me parler des produits \"et se met √† me toucher les seins #balancetonporc\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "C'est une agression sexuelle embraser une pets contre son consentement espece de porc @PierreMenes !!! √áa toujours √©t√© une agression sexuelle complice inf√¢me @canalplus ü§Æü§Æü§Æü§Æ #PierreMenesOut  #balancetonporc https://t.co/uALtjVQpoX :QT: Ah bon j'ai pas le droit de soulever des jupes et d'embrasser des femmes de forces ? Oh la la, le monde a chang√© ! Gros d√©gueulasse va ü§Æ #TPMP #PierreMenesOut\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Marche aussi pour les mecs qui r√¢lent sur #balancetonporc https://t.co/8jj3aTp0mb\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Un magnifique projet tr√®s bient√¥t thanks @ambreleguilly thanks @noemie.de.lattre hairstyle and makeup @nallahsangare #feminist #journeeinternationaledesdroitsdesfemmes #metoo #memepaspeur #resilience #sorority #model #ivorycoast #senegal #cotesdarmor #actress #writer #director https://t.co/LCm46glsJI\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#joyeusespaques #premieravril #jeremstargates #balancetonporc  #sondage vous faites quoi en premiers quand vous avez un kider surprise(follow,je fais des sondages)\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "@arthurberdah @ccornevin @AlbertZennou Il faut le stopper lui surtout le caillou dans la chaussure de Macron. √Ä chaque fois qu‚Äôil ouvrira la bouche on pensera √† ses services rendus contre du sexe. #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Colo kayak, seule fille, une nuit tout le groupe avec les mono, mega groping sur moi dans mon duvet. J'ai jamais rien dit.  #balancetonporc\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Bref, cette interview, n√©cessaire  √† mon sens, a confort√© mon avis sur cette affaire. √áa n'en fait √©videmment pas un coupable, au mieux un mauvais communiquant en revanche. #PPDA #Quotidien @Qofficiel #MeToo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "√Ä un moment donn√©, les r√©alisateurs tv vont arr√™ter de faire des plans en contreplong√©e pour mater sous les jupes des filles ? ü§î #TPMP #BalanceTonPorc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Certaines ne parlent pas de peur de ¬´ d√©truire la vie ¬ª bien en place de bon p√®re de famille ins√©r√© de l‚Äôagresseur, cela peut peut √™tre para√Ætre √©tonnant mais c‚Äôest un sentiment courant, cela renvoie d‚Äôailleurs aux propos tr√®s d√©plac√©s qui ont eu cours lors de l‚Äô√©pisode #metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@Space_Marcel @RHvitserk @crue_carmen @Le___Doc Ce qu'il faut que vous compreniez c'est le discours f√©ministe. Vous ne reconnaissez pas le syst√®me patriarcal dans lequel on vit ni la perspective de genre et forc√©ment, vous ne pouvez avoir aucune compr√©hension du mouvement #metoo autre que: elles veulent la guerre des sexes\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Catherine Deneuve et Brigitte Bardot moqu√©es dans une √©mission am√©ricaine pour leurs positions sur #BalanceTonPorc https://t.co/gBQHbErWkR\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Cor√©e du Sud: une irr√©ductible de Samsung est la championne #MeToo https://t.co/JTEMJELsXg\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc C'est pas gentil pour les cochons... üê∑üêñ\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#metoo oops #mytho...\"avant √ßa passait cr√®me Cyril\" duxit Pierre Men√©s sur @Cyrilhanouna https://t.co/nx14Rz0ydT :QT: üá´üá∑ FLASH - Pierre #M√©n√®s se d√©fend ce soir dans #TPMP : ¬´ Il faut prendre les gens comme ils sont, j'ai √©t√© embauch√© parce que je suis un personnage ¬ª. ¬´ Si je ne peux plus chambrer une meuf parce que c'est une meuf, c'est insupportable ¬ª, a-t-il ajout√©. (interview) https://t.co/QLeIzByREW\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@PCF Pourquoi le parquet / procureur n'a pas poursuivi le violeur ?  Les juges doivent r√©pondre de leurs actes !   #responsabilit√© #pedocriminalit√© #metoo #balancetonporc #viols #Gailhaguet #justice\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@f_letellier @jeanvaljean2018 @GwennB_ Certes, apr√®s, il y a des gens qui se consacrent √† plus d√©fendre, les femmes, ou les enfants ou, d autres, des associations qui se d√©vouent pour leur cause sans pour autant remettre en doute la parole des uns ou des autres comme √ßa a √©t√© le cas pour #MeToo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le #Iwas il me brise le coeur, vous √™tes tous/tes fort(e)s et extr√™mement courageux(ses), je vous souhaite le meilleur ü•∫‚ù§Ô∏è\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le poulet a merite les coups de poings qu'il a pris car desole mais on est pas la pour prendre des coups donc ce sera coup pour coup La police a baisser dans l'estime des francais. #libertepourdettinger #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Merci √† @AbouDjaffar de RT #balancetonporc, √ßa m'√©vite de cliquer sur le hashtag et d'en d√©couvrir encore plus‚Ä¶ #naus√©e\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ta_malou @avec_marine Elle aime les enfants la preuve elle s en es occup√© aux lyc√© de cette nouille de #macron brizitte devrais figur√© dans #BalanceTonPorc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "A song against Violence / Un titre qui vous prend aux tripes \"Violent &amp; Happy\" de La Nouvelle Eve sur #SoundCloud ? #np https://t.co/FZiTWLPrlZ #violence #violenceconjugale #violenceathome #stayhome #music #resteralamaison #covid #corona #covid19 #bjork #bj√∂rk #metoo\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Les t√©moignages du #MetooInceste sont juste gla√ßants. Les pr√©dateurs sexuels ne sont jamais tr√®s loin .\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Donc le collectif #MeToo d√©montre sa b√™tise abyssale et son manque de discernement. üòâ #QuandOnEstConOnEstCon https://t.co/DUGBqqLgqa\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@Lotisauteur @Mediapart Oui. J'ai √©t√© contact√© pour @BalanceTonPost et @TPMP notament et √† l'√©tranger pour parler de #MeToo. Quand je parlerai, je parlerai aussi de √ßa\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Je viens de l'√©couter. Encore une fois, excellente intervention de @Ovidieofficiel qui a raison sur la vraie pollution du d√©bat (plus que n√©cessaire) ouvert par les #MeToo #Balancetonporc #TIMESUP .  Cette tribune du Monde ne fait que brouiller/salir toute vraie discussion. https://t.co/MVfkNqm3eB\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Ce matin, on rigole bien sur FB. Et tout √ßa avant mon 2e caf√© #metoo #enitalien https://t.co/w6oA8YIHDo\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Vatican. La derni√®re bataille de Beno√Æt XVI - Courrier International Blogs https://t.co/ILVd5Ry3XU #metoo https://t.co/5SoPW4oqaG\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#metoo #metooinceste  \"prophet\":  4min24sec, pendant quelques secondes, il est comme De Niro parfois:   COMPLIQUE: je vous ecoute: je vous donne le pouvoir d'etre celui qui DOIT vous ecouter  A 16 ans, mes amis disait que j'etais comme lui dans \"Voyage au bout de l'enfer\",PARFOIS https://t.co/p42cEijVul\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Si il est prouv√© que Sandra Muller  @LettreAudio  A DE GROS SEINS, il demeure incompr√©hensible qu'Eric Brion ai eu envie de se taper cette grosse truie #balancetonporc #journeemondialedesanimaux\n",
      "√©\n",
      "Label pour le tweet suivant :\n",
      "‚ÄúEn allant vers l'h√©micycle,@jeanlassalle m'a mis une main aux fesses.‚ÄúJulia Castanier se confie. #balancetonporc https://t.co/2ybbTRj5sq\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@WiretteNicorett @fabfluckiger Quand tu dis que √ßa se travaille, √† quel degr√© il est n√©cessaire de commencer un traitement ? Et avec qui ?  #MeToo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Quand on te demande ton 06 dans la rue, que tu d√©clines ou ignores pour finalement te faire insulter de pute... üò© #balancetonporc\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "√Ä 21h, le #doc ¬´ Beauvoir, l‚Äôaventure d‚Äô√™tre soi ¬ª  üë©‚Äçüè´ √Ä l‚Äôheure des d√©bats sur la domination masculine, la charge mentale, #MeToo, quelle est la modernit√© de Simone de Beauvoir ?  üëâ Avec Le√Øla Slimani, Elisabeth Badinter et @titiou Lecoq  R√©al Fabrice Gardel et @MathieuWeschler https://t.co/laqKrJzFBi\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Nouvelle plainte pour #viol contre #Tariqramadan #Ramadan #balancetonporc https://t.co/GMJT3S1oBM\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Donc chacun ne voit pas la m√™me chose concernant 1er moiti√© du James Bond et deuxi√®me moiti√© du film loque humaine merci #metoo https://t.co/3PLromOFdX\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label pour le tweet suivant :\n",
      "@Bloom12005028 Formidable merci. Oui il faut imp√©rativement tout faire pour r√©former la l√©gislation sur le #viol au #Japon qui d√©j√† n'avait pas √©t√© modifi√©e, il y a peu, depuis 110 ans... #Scandale #MeToo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le cas Aziz Ansari questionne intelligemment le mouvement #MeToo https://t.co/XWWojlDtJ2 https://t.co/hpL0NMZqwd\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@CNEWS @angele_vl Une vraie rebelle cette meuf ! üòÜ Chanson sur #balancetonporc pr surfer sur la vague, chanson sur le r√©chauffement en pleine canicule wow. J'annonce un prochain titre sur la p√™che au homard et sur les vignettes Crit'Air mdrrr #risquez√©ro\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "\"Preuve que les questions li√©es aux femmes ont domin√© l‚Äôann√©e, les mots-clefs les plus utilis√©s sur Twitter en 2018 place ¬´ school #MeToo ¬ª, ¬´ feminist ¬ª et ¬´ molka ¬ª\".  Cet article date d'il y a un an, qu'en est-il pour 2019? ü§î #digipolUCLouvain https://t.co/FEyFo3NoDW\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc ce soir dans derni√®re minute\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#Gilead ne l√¢che pas l‚Äôaffaire contre @raoult_didier  √áa fait pls mois que c un feu roulant continu. Mais un truc comme √ßa garantit des dommages collat√©raux ou alors il faudra un tri s√©lectif des d√©nonciations anonymes (DAs). Apr√®s les #metoo, Les DAs sont maintenant la norme. ü•∂ https://t.co/U9MZGxZ56K :QT: Dites-moi que c'est un fake! https://t.co/EM3WkFHBqo Y aurait-il des fonctionnaires visant des promotions en essayant de se faire bien voir en incitant √† la d√©lation.Opposer m√©decins et pharmaciens, pas forc√©ment une strat√©gie gagnante, et en tout cas pas au service des patients. https://t.co/ikc6v1MHSX\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "#Iwas 15, 16, 17, deux fois le m√™me gros connard\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "2.2- #metoo #metooinceste   NOTES P√âDOPHILES  Il a fallu que je me d√©barrasse de le personne qui a peut-√™tre le plus de nonSoi que je connaisse et qui me pose beaucoup trop de probl√®me: j'ai d√©mont√© son ramassis de pr√©tention et d'apparences ridicules.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Agression et harc√®lement sexuels: le photographe star Patrick Demarchelier accus√©, Anna Wintour mise en cause https://t.co/4Z3wnQTXWy #metoo #Demarchelier #Wintour https://t.co/M2Kbd93WtK\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Un an apr√®s #MeToo, retrouvons-nous pour dire üõë STOP aux violences  sexistes et sexuelles. RDV samedi 29 septembre, √† 14h30, place de la  R√©publique, pour un die-in g√©ant.  üìÖ √âv√©nement Facebook : https://t.co/eVUsV1tczD üëâ Inscriptions : https://t.co/y0dJaQCalu https://t.co/gNnUP7YzXt\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc, √ßa balance pas mal √† Paris, √ßa balance pas m√¢le‚Ä¶ https://t.co/EFyUSn9Pf8 https://t.co/LlpDsgYjbH\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "J'avais 2 ans. C'√©tait le fils d'un ami de la famille : il en avait entre 11 et 13. Je l'ai recrois√© il y a 3 ans : il a maintenant 40 ans et m'a regard√© en mode \"tu te souviens\" avec son regard de pervers.  J'ai port√© la culpabilit√© de son acte pendant 30 ans. #metooinceste\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Avec mon b√©b√© de 8 mois dans son landeau.Un type approche:c'est une fille ou un gar√ßon? Moi:une fille.Lui:une future suceuse #balancetonporc\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Le pr√™tre de Trois-Rivi√®res a tent√© de mettre fin √† ses jours - RCI https://t.co/8Zsk7oQnz9 #metoo https://t.co/r0dkl00Pla\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Des suffragettes √† #MeToo : le violet, couleur iconique des mouvements f√©ministes https://t.co/Jeu0Cb216y @letemps #soc\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#Metoo Les f√©ministes radicales de gauche de plus en plus critiqu√©es par des...f√©ministes....https://t.co/hQLAbzqHDg via @lp_lapresse\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@YannisPSD @_Ecce__Homo_ @MarleneSchiappa \"#S√©n√©galüá∏üá≥ : #Macronüá´üá∑ et #Rihanna saluent un nouvel √©lan pour l‚Äô√©ducation\"  #Schiappa @Elysee #BrigitteMacron #France #Paris #LREM #EnMarche #LaREM #BalanceTonPorc https://t.co/BPJXRAnkNa\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Hanouna avec capu anav et lors de l‚Äôentretien d embauche d enora #balancetonporc@hanouna@c8\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "üî¥Notre tribune dans @libe  ‚û°Ô∏è\"Violences Sexuelles sur mineur.e.s : l‚Äôheure de la tol√©rance z√©ro a sonn√©\"üîî   #justicepourjulie #metooinceste  Avec @memoiretrauma @MiKohiyama @AndreaBescond @Abitbol_sarah @corinne_leriche @aludv P. √â. Germain Thill  üìå https://t.co/tSxr6LHm28 https://t.co/qpTnlxJ2BS\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "https://t.co/Ezz6jd3MjO Oui je l'adore üíôüéµüé∂ Je ne suis pas #MeToo https://t.co/QTzSFXWAFH\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@MiKohiyama Pas que dans le sport, pas que dans le cin√©ma, les porcs ne sont pas tous sous les projecteurs mais ils sont partout dans nos vies de tous les jours, tout pr√®s et les victimes aussi...üò¢#metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Pourquoi certaines enqu√™tes sont-elles d'utilit√© publique ? Pour que des anonymes ne s'autorisent plus de traiter des victimes potentielles de \"femelles\" hyst√©riques. Les enqu√™tes permettent d'ouvrir des enqu√™tes, qui d√©montrerons ou non la culpabilit√© ou l'innocence. #MeToo https://t.co/06RIyrKGBG\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Bordel j'suis dans l'EHPAD de mon grand-p√®re.. putain si les soignantes participaient au hashtag #balancetonporc mdddddr √ßa aurait saturer Twitter\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#√©v√©nement R√©putation Time 2017 : du tweet #balancetonporc √† la couverture du Elle, anatomie d‚Äôune lev√©e de boucliers g√©n√©ralis√©e. C'est demain avec @annatwit #RepTime2017  En savoir plus &gt; https://t.co/Z0nGlUq457  Programme et inscription &gt; https://t.co/gP3b4GM9CP https://t.co/V6BsQrFcnR\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "labeliser_tweet(df, nb_tweets=100, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jAyzaJ5875dw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = df_label.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label.drop(1979)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282587829357490179</td>\n",
       "      <td>Vous ne connaissez pas de coll√®gues qui ont √©t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1374666678533951488</td>\n",
       "      <td>-Jsais profiter de ma notori√©t√© pour agresser ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463447795877265410</td>\n",
       "      <td>#metoo #metooinceste  Excusez-moi, j'avais pr√©...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1305966401887371264</td>\n",
       "      <td>#MeToo Je zappe : les femmes d√©fendues √† la t√©...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1350452454782070786</td>\n",
       "      <td>#metooinceste #NousToutes @memoiretrauma  Je n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>1583880474371366912</td>\n",
       "      <td>https://t.co/Ezz6jd3MjO Oui je l'adore üíôüéµüé∂ Je ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>1223244528469139456</td>\n",
       "      <td>@MiKohiyama Pas que dans le sport, pas que dan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>1464357942224953347</td>\n",
       "      <td>Pourquoi certaines enqu√™tes sont-elles d'utili...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1023147865772838912</td>\n",
       "      <td>Bordel j'suis dans l'EHPAD de mon grand-p√®re.....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>942742552150757376</td>\n",
       "      <td>#√©v√©nement R√©putation Time 2017 : du tweet #ba...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2006 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0     1282587829357490179  Vous ne connaissez pas de coll√®gues qui ont √©t...   \n",
       "1     1374666678533951488  -Jsais profiter de ma notori√©t√© pour agresser ...   \n",
       "2     1463447795877265410  #metoo #metooinceste  Excusez-moi, j'avais pr√©...   \n",
       "3     1305966401887371264  #MeToo Je zappe : les femmes d√©fendues √† la t√©...   \n",
       "4     1350452454782070786  #metooinceste #NousToutes @memoiretrauma  Je n...   \n",
       "...                   ...                                                ...   \n",
       "2005  1583880474371366912  https://t.co/Ezz6jd3MjO Oui je l'adore üíôüéµüé∂ Je ...   \n",
       "2006  1223244528469139456  @MiKohiyama Pas que dans le sport, pas que dan...   \n",
       "2007  1464357942224953347  Pourquoi certaines enqu√™tes sont-elles d'utili...   \n",
       "2008  1023147865772838912  Bordel j'suis dans l'EHPAD de mon grand-p√®re.....   \n",
       "2009   942742552150757376  #√©v√©nement R√©putation Time 2017 : du tweet #ba...   \n",
       "\n",
       "     label  \n",
       "0        2  \n",
       "1        2  \n",
       "2        2  \n",
       "3        2  \n",
       "4        3  \n",
       "...    ...  \n",
       "2005     1  \n",
       "2006     2  \n",
       "2007     2  \n",
       "2008     2  \n",
       "2009     2  \n",
       "\n",
       "[2006 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "mRUK1kmZ7_z8",
    "outputId": "78d2f214-ea47-47f1-d388-9679b8d6d384",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1266\n",
       "1.0     394\n",
       "3.0     172\n",
       "0.0      75\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hnt-ro2_WpXz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 10\n",
    "MAX_LEN = 300\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-JvbX630WUHn",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89b418bcc7a451bafbe2cd902834364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)tencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e772c93523cb48b8a869f49574739852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f574914b8f4115a1a855f739e921d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=4)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=10e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "cQS2l-oQZwmL",
    "outputId": "ab347867-6f13-41ee-9457-1ea3ef877c2f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "text = df_label['text'].to_list()\n",
    "labels = df_label['label'].to_list()\n",
    "\n",
    "#user tokenizer to convert sentences into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Ge4RCSKcZztV",
    "outputId": "47bd58fd-bb54-45c5-b011-e4af769fcee9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.4, stratify = labels)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "pbFcqTLYWnIZ",
    "outputId": "ca5a0099-dba7-4b4e-ad98-14b46dbb3819",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2618875404198964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|‚ñà         | 1/10 [11:58<1:47:46, 718.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 1.0668712556362152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|‚ñà‚ñà        | 2/10 [26:31<1:47:53, 809.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 0.957703024148941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|‚ñà‚ñà‚ñà       | 3/10 [41:12<1:38:15, 842.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 0.8441829631725947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [56:13<1:26:33, 865.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7936197916666666\n",
      "Train loss: 0.7229040463765463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [1:11:12<1:13:06, 877.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7316261574074074\n",
      "Train loss: 0.6163275490204493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [1:25:21<57:51, 867.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7779947916666666\n",
      "Train loss: 0.5189388146003088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [1:38:30<42:06, 842.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8236400462962963\n",
      "Train loss: 0.4161665042241414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [1:46:59<24:32, 736.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8298611111111112\n",
      "Train loss: 0.3496982256571452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [1:54:01<10:37, 637.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8383969907407407\n",
      "Train loss: 0.2971478613714377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [2:00:39<00:00, 723.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8423032407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_set=[]\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels.long())\n",
    "        loss = outputs[0]\n",
    "        train_loss_set.append(loss.item())    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs =  model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels.long())\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    # mettre le mod√®le en mode d'√©valuation\n",
    "    model.eval()\n",
    "    \n",
    "    # stocker les pr√©dictions de tous les batchs dans une liste\n",
    "    predictions = []\n",
    "    \n",
    "    # boucle sur les batches dans le dataloader de test\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        # d√©placer les donn√©es sur le m√™me dispositif que le mod√®le\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # d√©sactiver le calcul des gradients pour √©conomiser de la m√©moire et acc√©l√©rer les calculs\n",
    "        with torch.no_grad():\n",
    "            # faire passer les donn√©es √† travers le mod√®le pour obtenir les logits\n",
    "            outputs =  model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            logits = outputs[0]\n",
    "    \n",
    "        # appliquer la fonction softmax pour obtenir les probabilit√©s pour chaque classe\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # convertir les probabilit√©s en pr√©dictions en prenant l'indice de la classe avec la probabilit√© la plus √©lev√©e\n",
    "        batch_preds = torch.argmax(probs, dim=1)\n",
    "        \n",
    "        # ajouter les pr√©dictions pour ce batch √† la liste de pr√©dictions globale\n",
    "        predictions.extend(batch_preds.cpu().numpy().tolist())\n",
    "    \n",
    "    # retourner la liste de pr√©dictions globale\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions_val \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 18\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# d√©sactiver le calcul des gradients pour √©conomiser de la m√©moire et acc√©l√©rer les calculs\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# faire passer les donn√©es √† travers le mod√®le pour obtenir les logits\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# appliquer la fonction softmax pour obtenir les probabilit√©s pour chaque classe\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:1084\u001b[0m, in \u001b[0;36mCamembertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1084\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1096\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:904\u001b[0m, in \u001b[0;36mCamembertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    895\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    897\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    898\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    899\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    903\u001b[0m )\n\u001b[0;32m--> 904\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    917\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:541\u001b[0m, in \u001b[0;36mCamembertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    532\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    533\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    534\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    539\u001b[0m     )\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 541\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:467\u001b[0m, in \u001b[0;36mCamembertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    464\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    465\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 467\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:479\u001b[0m, in \u001b[0;36mCamembertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 479\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:377\u001b[0m, in \u001b[0;36mCamembertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 377\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions_val = predict(model, validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 17, 1.0: 100, 2.0: 343, 3.0: 42}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(validation_labels.numpy(), return_counts=True)\n",
    "label_counts = dict(zip(unique, counts))\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(validation_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['Autre','Presse','Opinion','T√©moignage'], \n",
    "                     columns = ['Autre','Presse','Opinion','T√©moignage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True, cbar = False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
