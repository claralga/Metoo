{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kV9SWKZSWAh0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 16:09:19.746222: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 16:09:22.015761: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "#from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pADt5CykCKaz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labeliser_tweet(df, nb_tweets=5, random_state=0):\n",
    "    \n",
    "    # Vérifier si le fichier \"label.csv\" existe et charger les tweet_id déjà labelisés\n",
    "    tweets_labelises = set()\n",
    "    try:\n",
    "        with open('label.csv', mode='r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                tweets_labelises.add(row['tweet_id'])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    # Sélectionner un échantillon aléatoire de tweets non encore labelisés\n",
    "    df_a_labeliser = df[~df.index.isin(tweets_labelises)].sample(n=nb_tweets, random_state=random_state)\n",
    "    \n",
    "    # Labeliser les tweets sélectionnés et enregistrer les labels dans un fichier CSV\n",
    "    with open('label.csv', mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if f.tell() == 0:\n",
    "            writer.writerow(['tweet_id', 'text', 'label'])\n",
    "        for tweet_id, text in df_a_labeliser['text'].items():\n",
    "            label = input(f'Label pour le tweet suivant :\\n{text}\\n')\n",
    "            # Écrire les données labelisées dans le fichier CSV\n",
    "            writer.writerow([tweet_id, text, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "fGUP7YlcanuW",
    "outputId": "9d6da307-a96e-45dc-ca7f-acd015856f90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_concat_clean/base_annotation_fev23.csv', index_col='tweet_id').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKjOXzht-kvr",
    "outputId": "18bd519c-92df-4ce6-c15c-ec4555f02a8c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label pour le tweet suivant :\n",
      "Affaire #AdèleHaenel : le réalisateur #ChristopheRuggia placé en garde à vue #MeToo https://t.co/6daXmWhTqK\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Un pain au chocolat peut-il permettre de se faire pardonner une agression sexuelle? #Haziza #balancetonporc https://t.co/g8YGxBzeJM\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@CordaniOfficiel Comme je vous comprends....j'ai le même problème avec le mois de février....courage #MeToo #MeTooInceste #metoosuisse #suisse #inceste #silence #maltraitance\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Publication livre : \"Ni pantins ni soumis\" ou les excès du #METOO  https://t.co/B0YvW5GyXA @libgallimard https://t.co/PcE29MWuPs\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "*ⒸⒸ➥ #Venezuela ☛ Communist psychopaths | https://t.co/iFKJd7x2Kb | #Residente #RenéPérez #UnicefComunista #Unicef #JairBolsonaro #FernandoAlbán #Brasil #BrieLarson #BenicioDelToro #MeToo #AngelinaJolie #ACNUR #CateBlanchett #LGBT #Comunismo #Anticomunismo https://t.co/XmQppraaNU\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "@briefmenews en effet, vs avez raison. Tant mieux, ça me permet de continuer à vs lire avec confiance. Suoer récap sur l'Algérie ds le dernier Brief. Je compte sur vs pr faire un aussi bon brief sur #MeToo et #IDidntReport\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Un budget qui va titiller le scrotum des français, sans les toucher, normal ça fait bien longtemps qu'ils n'en n'ont plus ! #metoo https://t.co/PUFgeryO88\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Il y a des œuvres qui au delà de leurs beautés ont une force cathartique societale poétique indispensable Merci @AndreaBescond  #ericmetayer  la reconstruction est possible #metoo #JeSuisVictime #psychanalyse #stopviolencesfaitesauxenfants #imprescriptibilité https://t.co/RCedpIqc3O :QT: En 2016, un ovni débarquait au Petit @TMontparnasse. Ovationné chaque soir par un public bouleversé.  Couronné par le Molière du seul/e en scène, #LESCHATOUILLES d’@AndreaBescond, mise en scène @Metayereric, est exceptionnellement en ligne jusqu’au 3/05 !  https://t.co/vriKkmkAZI\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#metoo Alors pour 16 -18, en ce moment precis, (3:07 le 25/07/202i) je ne sait pas les appeler. Je suis nul en orthographe et fort en grammaire quand j'étais à l 'école primaire. je ne sais pas pourquoi je dis cela.\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "VIDEO TPMP People : vifs échanges sur le plateau autour du mouvement #MeToo https://t.co/XT1pzDczgG https://t.co/JFOpEcFB7A\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc : on démon les porcs sans dénoncer la porcherie #RTLMatin @MadeJessey #SensCommun #LR\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@MarleneSchiappa @EPhilippePM @NadiaHAI78 @MarleneSchiappa  Quand allez-vous porter secours aux enseignantes violentées par leur  chef d'établissement et aux lanceurs d'alerte  réprimés par @EducationFrance @justice_gouv ?   Merci de cesser de conforter l'Omerta.   #metoo #PasdeVague #NousToutes   https://t.co/LXngHxIYrA\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Absolution accordée à un agresseur sexuel : le DPCP fera appel https://t.co/pTxhlpwpjS #Québec #polqc #simonhoule #TroisRivieres #AgressionNonDenoncee #MeToo #JusticeQc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "The Les concernés Daily est en ligne! https://t.co/57GQC6LQR8 #afp #metoo\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@Frambwazz @doucefrance13 @MonsieurAbdool La différence c'est que le BalanceTonYoutubeur c'est que le youtubeur il se sert de sa notoriété et de la faiblesse psychologique de ses fans. Un random c'est dans #BalanceTonPorc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Sarah Palin Compares Sacha Baron Cohen Duping Politicians to #MeToo https://t.co/GuJdeW4Ohr https://t.co/DjVxDR68uK\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Le gouvernement est aveugle aux aspirations de la jeune génération #MeToo, par Les invités de Mediapart via @MediapartBlogs https://t.co/95htIrxLHZ\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@tweekette75 @MaitreKlem @HutzLionel1 @Brujulasegunda @Le___Doc @immaterielle @sui_gene_ris @Kdet_Rousselle Je ne pense pas avoir écrit à un seul moment LES Gyneco dans leur ensemble. LA profession de Gyneco. Je visais ce monsieur et ces comparses.  mais répondre #NotAllGyneco quand on parle problèmes IVG et violences Gyneco est pour moi du même niveau que #NotAllMen contre #MeToo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#MeToo : le studio Weinstein vendu à une société d'investissement https://t.co/mD8XellyGu via @Culturebox\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "En 93 déjà, 72% des femmes avait subi un acte de #harcèlement sexuel dit L. Bertalli #RTSinfrarouge #MeToo https://t.co/9yzIJgkAXD\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le mec de 50 ans au bar qui m'a dit que je mettais du rouge à lèvres uniquement pour allumer les mecs #balancetonporc\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Je me suis toujours dit, elles ont fait un #BalanceTonPorc , qu'est ce qui se serai passé si on avait fait un #BalanceTaPute ?\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ginmedaddy Dans ce cas va écrire sur #BalanceTonPorc. A moins que ton prêtre est une pouffe ce que j'en doute?  Vous les femme vous ête toutes les même, vous ne RESPECTEZ RIEN #BalanceTonPorc=Injustice faite aux femmes par les hommes #BalanceTaPouffe=Injustice faite aux hommes par les femme\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "avec #MeToo on parle de crimes : viols, agressions sexuelles etc. On parle de choses qui sont punissables par la loi (même si on sait tous-tes ce que ça donne) du coup je vois mal comment on peut parler de délation alors qu'on dénonce des pratiques punissables\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#WaltDisney - Le prince de \"La Belle au bois dormant\" est-il un prédateur sexuel ? https://t.co/jDbKD9RHJI via @franceculture #Jeunesse #Conte #Féminisme #BalanceTonPorc https://t.co/IvGS6GD1Jn\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#MeToo #metooinceste et #MeTooGay offrent aussi une opportunité de penser l’oppression que peut représenter le silence et le pouvoir de la parole (mais aussi ses limites). La parole libère mais elle n’efface pas l’irrévocable d’un acte terrible. Elle est cri de justice !\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "J'écoute #Jablonka depuis 10 min, il y a rien qui va. Le mec il n'a pas dû lire un seul truc écrit par des féministes depuis #metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Accusé d'harcèlement sexuel, le maire de Copenhague démissionne en pleine nouvelle vague de #Metoo au Danemark https://t.co/ZPYKZXneHs via @rtbfinfo\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc un nouveau hashtag à la #agressionnondenoncee\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "le nombre de #Iwas ca me brise le coeur\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@GG_RMC @DICKENSDAVID1 et la peur ? tu connais ? elle a peut être trouvé le courage de dénoncer en voyant le mouvement actuel #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Ceci EST une agression sexuelle.  Aucun débat. #balancetonporc https://t.co/NYJl1aguRV\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc j'ai été violé par le chien de Michel Drucker\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Baisse des crédits du programme 137. Annonces du Grenelle non financées. Manque de moyens des associations malgré la hausse de leur activité consécutive à #metoo. La vérité sur les #bullshit du gouvernement, dans le rapport de la très rigoureuse commission des finances du Senat! https://t.co/hTxKV5olvF :QT: La commission des finances du Sénat assez sèche sur \"le milliard d'euros\" pour l'égalité femmes hommes https://t.co/VK7nBOt2BZ https://t.co/p9Bv5jiX5A\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "En France on as vraiment un probléme.On est complétement passer à coté du mouvement #MeToo et on as donné le césar à Roman Polanski. Et là on est sur le point de passer à coté, de ce mouvement historique de justice contre le racisme. Je comprends vraiment plus rien à ce pays.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Après #MeToo / #BalanceTonPorc autour de #BalanceTonYoutubeur qui fait exploser #twitter ! Encore une fois faut prendre du recule pour ne pas faire les mêmes erreurs qui ont déjà été commise. #Squeezie :QT: Les YouTubers (y compris ceux qui crient sur tous les toits qu’ils sont féministes) qui profitent de la vulnérabili… https://t.co/B7VGErsR2z\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ATrapenard @Giulia_Fois_ @fabricearfi @marineturchi  Merci de RT🙏 La #pédocriminalité est un fléau avec desconséquences colossales sur la vie des #victimes. Besoin de #politiques publiques à la hauteur. #Iwas #StopPrescription St⛔️p #ViolencesSexuelles https://t.co/MtGmQlr7T1\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Waw ces anecdotes gravissimes sur ce HT #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le secret d'une vie bien menée c'est qu'elle soit bien remplie. #denoncetonporc #denoncetatruie #balancetonporc #Metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "\"Je me suis vraiment sentie salie\" : paroles d'éditrices à propos des violences sexistes et sexuelles dans le milieu littéraire https://t.co/717XebvMbp via @franceinfo #sexisme #féminisme #ViolenceMasculine #metoo #BalanceTonPorc\n",
      "\n",
      "Label pour le tweet suivant :\n",
      "#metoo #metooinceste #CONSISTENCY  UN JEU DIFFÉRENCE COULEUR/TEXTE  https://t.co/hA0D41vxZz\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "@ericrevel1 Et en cette période #metoo, un tel obsédé aurait pris cher. Toutes les qualités ce mec.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc alors au lieu de demander des noms, rendez-vous compte du nombre de témoignages, de l'horreur quotidienne que c'est.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Indescencence: croire que ne pas être agresseur mérite d'être célébré...  #balancetonporc https://t.co/vHsE3rYsx2\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@s_cluzel @N_Hulot Bravo! Encore une fois, notre gouvernement marque sa bonne marche dans la gestion des affaires publiques et de la séparation des pouvoirs. #mercipourcemoment #BalanceTonPorc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ellensalvi En somme #metoo a raison quand ses accusateurs (trices) accusent. Et #metoo a raison quand ses acusateurs publics (trices/ques) sont demasqué(e)s. Quoi qu’il arrive, #metoo a raison.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "https://t.co/Ee9Dpul3ph Des méthodes vraiment pré #MeToo pour acquitter les flics accusés du #violDu36 : fouiller dans la vie de la victime pour la dénigrer, l'accuser d'être ivre, l'accuser de confusion (stress post-trauma). Le #patriarcat a la vie dure, surtout dans la justice.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@CBouanchaud Quelqu’un pour m’expliquer pourquoi il y a toujours un moment de représentation hypersexualisée ? Avec #metoo, la parole et une réflexion en profondeur sur les actes er la société semblaient prendre le dessus, mais on revient à des demonstration sexualisée. Pige pas.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Les valeurs 2 @Zemmour ce n'est pas celles de notre république mais bien celles du fais ce que je dis mais pas ce que je fais Coucher avec son conseillère qui est sa subordonnée n'est pas républicain  #MeTooPolitique #balancetonporc Pensée à sa femme victime du grand remplacement :QT: #Mohamed VS #Zemmour   ➡️ Plus d’un million de vues sur mon compte #TikTok (https://t.co/huGJi7dGp4).   Merci ! https://t.co/8JYA7SB9Uo\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Super doc post #metoo en préparation pour LCP, suivez le compte sur insta ! (Et pi c'est une copine)  https://t.co/QVxkB0zReI\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "labeliser_tweet(df, nb_tweets=50, random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jAyzaJ5875dw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "mRUK1kmZ7_z8",
    "outputId": "78d2f214-ea47-47f1-d388-9679b8d6d384",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2.0    828\n",
       "1.0    270\n",
       "3.0    113\n",
       "0.0     42\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = df_label.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hnt-ro2_WpXz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 10\n",
    "MAX_LEN = 300\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-JvbX630WUHn",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89b418bcc7a451bafbe2cd902834364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e772c93523cb48b8a869f49574739852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f574914b8f4115a1a855f739e921d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=4)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=10e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "cQS2l-oQZwmL",
    "outputId": "ab347867-6f13-41ee-9457-1ea3ef877c2f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "text = df_label['text'].to_list()\n",
    "labels = df_label['label'].to_list()\n",
    "\n",
    "#user tokenizer to convert sentences into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Ge4RCSKcZztV",
    "outputId": "47bd58fd-bb54-45c5-b011-e4af769fcee9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.4)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "pbFcqTLYWnIZ",
    "outputId": "ca5a0099-dba7-4b4e-ad98-14b46dbb3819",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2618875404198964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [11:58<1:47:46, 718.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 1.0668712556362152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [26:31<1:47:53, 809.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 0.957703024148941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 3/10 [41:12<1:38:15, 842.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 0.8441829631725947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 4/10 [56:13<1:26:33, 865.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7936197916666666\n",
      "Train loss: 0.7229040463765463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 5/10 [1:11:12<1:13:06, 877.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7316261574074074\n",
      "Train loss: 0.6163275490204493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 6/10 [1:25:21<57:51, 867.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7779947916666666\n",
      "Train loss: 0.5189388146003088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 7/10 [1:38:30<42:06, 842.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8236400462962963\n",
      "Train loss: 0.4161665042241414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 8/10 [1:46:59<24:32, 736.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8298611111111112\n",
      "Train loss: 0.3496982256571452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 9/10 [1:54:01<10:37, 637.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8383969907407407\n",
      "Train loss: 0.2971478613714377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [2:00:39<00:00, 723.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8423032407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_set=[]\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels.long())\n",
    "        loss = outputs[0]\n",
    "        train_loss_set.append(loss.item())    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs =  model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels.long())\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8221643 , -0.83890676,  2.5219278 , -0.92354465],\n",
       "       [-0.81028825, -1.07352   ,  2.5322819 , -0.725595  ],\n",
       "       [-0.34867215,  2.070702  , -0.7203709 , -0.78563815],\n",
       "       [-0.38904977,  2.0407073 , -0.5774643 , -0.8829936 ],\n",
       "       [-0.37330586,  2.0593083 , -0.645782  , -0.8296578 ],\n",
       "       [-0.36106187,  2.0633984 , -0.67290175, -0.81339943],\n",
       "       [-0.8287327 , -0.91648006,  2.538202  , -0.8618867 ],\n",
       "       [-0.80881274, -1.1790465 ,  2.467678  , -0.56627357],\n",
       "       [-0.47179356,  2.0046434 , -0.36589116, -0.96706545],\n",
       "       [ 0.13611896, -0.89000213, -0.81778085,  1.5121919 ],\n",
       "       [-0.5510757 , -1.6220843 ,  1.6150688 ,  0.41074413],\n",
       "       [-0.8388688 , -0.76494545,  2.5143547 , -0.95420045],\n",
       "       [-0.81536543, -0.94629   ,  2.535512  , -0.8548476 ],\n",
       "       [-0.82336545, -0.97191536,  2.546595  , -0.82897425],\n",
       "       [-0.87656933, -0.49813908,  2.4661756 , -1.1080488 ],\n",
       "       [-0.8113716 , -0.9549724 ,  2.5452538 , -0.85571337],\n",
       "       [-0.313241  , -1.5654745 ,  0.90972686,  0.85591567],\n",
       "       [-0.82185245, -0.77548176,  2.534844  , -0.9789212 ],\n",
       "       [-0.31588787,  2.0782387 , -0.8131522 , -0.74371976],\n",
       "       [-0.906727  ,  0.136479  ,  2.1084023 , -1.2957884 ],\n",
       "       [-0.3466072 ,  2.0709176 , -0.7266443 , -0.78978086],\n",
       "       [ 0.12745321, -0.8740188 , -0.8265506 ,  1.5019445 ],\n",
       "       [ 0.09549239, -0.9439918 , -0.70322037,  1.4987872 ],\n",
       "       [ 0.11192477, -0.9146199 , -0.7643703 ,  1.5037094 ],\n",
       "       [-0.7893951 , -0.93905354,  2.5125606 , -0.8641126 ],\n",
       "       [-0.79454863, -0.90420926,  2.535768  , -0.89576244],\n",
       "       [-0.7494637 , -1.2723875 ,  2.459231  , -0.56383413],\n",
       "       [-0.8151687 , -0.96693426,  2.5525303 , -0.83956957],\n",
       "       [-0.796139  , -0.920967  ,  2.541124  , -0.8812912 ],\n",
       "       [-0.61143947, -1.6351812 ,  1.8655634 ,  0.21725975],\n",
       "       [-0.3131526 ,  2.0723882 , -0.81363904, -0.73718274],\n",
       "       [-0.7997458 , -1.1139518 ,  2.4308772 , -0.60173714],\n",
       "       [-0.35464805,  2.0689168 , -0.7289603 , -0.7766812 ],\n",
       "       [-0.5733671 ,  1.7986631 ,  0.08574091, -1.1468596 ],\n",
       "       [-0.4635352 ,  1.9970679 , -0.3719347 , -0.93919075],\n",
       "       [-0.7964984 , -0.9275209 ,  2.5338733 , -0.87363356],\n",
       "       [-0.73766196, -1.4382079 ,  2.2940345 , -0.25399253],\n",
       "       [-0.81251603, -1.0391923 ,  2.5322132 , -0.7587744 ],\n",
       "       [-0.92036116,  0.24218182,  2.039402  , -1.2951918 ],\n",
       "       [-0.74385905,  0.12416483,  1.9623332 , -1.2434186 ],\n",
       "       [-0.9162116 ,  0.5680897 ,  1.8605716 , -1.3983872 ],\n",
       "       [-0.8068203 , -1.0083487 ,  2.5225716 , -0.8004366 ],\n",
       "       [-0.7893088 , -0.95427823,  2.5423083 , -0.85736024],\n",
       "       [-0.91950834,  0.3575328 ,  1.992028  , -1.3718396 ],\n",
       "       [-0.34458727,  2.0724235 , -0.7603166 , -0.7614318 ],\n",
       "       [-0.8525001 , -0.9911487 ,  2.5273418 , -0.75805795],\n",
       "       [ 0.06329463, -1.0494696 , -0.56660277,  1.4499758 ],\n",
       "       [-0.8466078 , -0.71145797,  2.5273762 , -0.9838972 ],\n",
       "       [-0.33588907,  2.0747738 , -0.7833482 , -0.747755  ],\n",
       "       [-0.91969585,  0.37546128,  1.8632278 , -1.2724297 ],\n",
       "       [-0.33518684,  2.0616288 , -0.72089446, -0.8081205 ],\n",
       "       [-0.80449706, -0.78376436,  2.533194  , -0.97836703],\n",
       "       [-0.78339136, -1.0119371 ,  2.5355659 , -0.82826006],\n",
       "       [-0.787206  ,  0.14527246,  1.9581571 , -1.2546949 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kgii8LE3Y6_N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
