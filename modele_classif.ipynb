{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "kV9SWKZSWAh0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "#from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "pADt5CykCKaz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labeliser_tweet(df, nb_tweets=5, random_state=0):\n",
    "    \n",
    "    # Vérifier si le fichier \"label.csv\" existe et charger les tweet_id déjà labelisés\n",
    "    tweets_labelises = set()\n",
    "    try:\n",
    "        with open('label.csv', mode='r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                tweets_labelises.add(row['tweet_id'])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    # Sélectionner un échantillon aléatoire de tweets non encore labelisés\n",
    "    df_a_labeliser = df[~df.index.isin(tweets_labelises)].sample(n=nb_tweets, random_state=random_state)\n",
    "    \n",
    "    # Labeliser les tweets sélectionnés et enregistrer les labels dans un fichier CSV\n",
    "    with open('label.csv', mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if f.tell() == 0:\n",
    "            writer.writerow(['tweet_id', 'text', 'label'])\n",
    "        for tweet_id, text in df_a_labeliser['text'].items():\n",
    "            label = input(f'Label pour le tweet suivant :\\n{text}\\n')\n",
    "            # Écrire les données labelisées dans le fichier CSV\n",
    "            writer.writerow([tweet_id, text, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "fGUP7YlcanuW",
    "outputId": "9d6da307-a96e-45dc-ca7f-acd015856f90",
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/data_concat_clean/base_annotation_fev23.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/data_concat_clean/base_annotation_fev23.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweet_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_concat_clean/base_annotation_fev23.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/data_concat_clean/base_annotation_fev23.csv', index_col='tweet_id').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKjOXzht-kvr",
    "outputId": "18bd519c-92df-4ce6-c15c-ec4555f02a8c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label pour le tweet suivant :\n",
      "Affaire #AdèleHaenel : le réalisateur #ChristopheRuggia placé en garde à vue #MeToo https://t.co/6daXmWhTqK\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Un pain au chocolat peut-il permettre de se faire pardonner une agression sexuelle? #Haziza #balancetonporc https://t.co/g8YGxBzeJM\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@CordaniOfficiel Comme je vous comprends....j'ai le même problème avec le mois de février....courage #MeToo #MeTooInceste #metoosuisse #suisse #inceste #silence #maltraitance\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Publication livre : \"Ni pantins ni soumis\" ou les excès du #METOO  https://t.co/B0YvW5GyXA @libgallimard https://t.co/PcE29MWuPs\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "*ⒸⒸ➥ #Venezuela ☛ Communist psychopaths | https://t.co/iFKJd7x2Kb | #Residente #RenéPérez #UnicefComunista #Unicef #JairBolsonaro #FernandoAlbán #Brasil #BrieLarson #BenicioDelToro #MeToo #AngelinaJolie #ACNUR #CateBlanchett #LGBT #Comunismo #Anticomunismo https://t.co/XmQppraaNU\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "@briefmenews en effet, vs avez raison. Tant mieux, ça me permet de continuer à vs lire avec confiance. Suoer récap sur l'Algérie ds le dernier Brief. Je compte sur vs pr faire un aussi bon brief sur #MeToo et #IDidntReport\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Un budget qui va titiller le scrotum des français, sans les toucher, normal ça fait bien longtemps qu'ils n'en n'ont plus ! #metoo https://t.co/PUFgeryO88\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Il y a des œuvres qui au delà de leurs beautés ont une force cathartique societale poétique indispensable Merci @AndreaBescond  #ericmetayer  la reconstruction est possible #metoo #JeSuisVictime #psychanalyse #stopviolencesfaitesauxenfants #imprescriptibilité https://t.co/RCedpIqc3O :QT: En 2016, un ovni débarquait au Petit @TMontparnasse. Ovationné chaque soir par un public bouleversé.  Couronné par le Molière du seul/e en scène, #LESCHATOUILLES d’@AndreaBescond, mise en scène @Metayereric, est exceptionnellement en ligne jusqu’au 3/05 !  https://t.co/vriKkmkAZI\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#metoo Alors pour 16 -18, en ce moment precis, (3:07 le 25/07/202i) je ne sait pas les appeler. Je suis nul en orthographe et fort en grammaire quand j'étais à l 'école primaire. je ne sais pas pourquoi je dis cela.\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "VIDEO TPMP People : vifs échanges sur le plateau autour du mouvement #MeToo https://t.co/XT1pzDczgG https://t.co/JFOpEcFB7A\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc : on démon les porcs sans dénoncer la porcherie #RTLMatin @MadeJessey #SensCommun #LR\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@MarleneSchiappa @EPhilippePM @NadiaHAI78 @MarleneSchiappa  Quand allez-vous porter secours aux enseignantes violentées par leur  chef d'établissement et aux lanceurs d'alerte  réprimés par @EducationFrance @justice_gouv ?   Merci de cesser de conforter l'Omerta.   #metoo #PasdeVague #NousToutes   https://t.co/LXngHxIYrA\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Absolution accordée à un agresseur sexuel : le DPCP fera appel https://t.co/pTxhlpwpjS #Québec #polqc #simonhoule #TroisRivieres #AgressionNonDenoncee #MeToo #JusticeQc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "The Les concernés Daily est en ligne! https://t.co/57GQC6LQR8 #afp #metoo\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@Frambwazz @doucefrance13 @MonsieurAbdool La différence c'est que le BalanceTonYoutubeur c'est que le youtubeur il se sert de sa notoriété et de la faiblesse psychologique de ses fans. Un random c'est dans #BalanceTonPorc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Sarah Palin Compares Sacha Baron Cohen Duping Politicians to #MeToo https://t.co/GuJdeW4Ohr https://t.co/DjVxDR68uK\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Le gouvernement est aveugle aux aspirations de la jeune génération #MeToo, par Les invités de Mediapart via @MediapartBlogs https://t.co/95htIrxLHZ\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@tweekette75 @MaitreKlem @HutzLionel1 @Brujulasegunda @Le___Doc @immaterielle @sui_gene_ris @Kdet_Rousselle Je ne pense pas avoir écrit à un seul moment LES Gyneco dans leur ensemble. LA profession de Gyneco. Je visais ce monsieur et ces comparses.  mais répondre #NotAllGyneco quand on parle problèmes IVG et violences Gyneco est pour moi du même niveau que #NotAllMen contre #MeToo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#MeToo : le studio Weinstein vendu à une société d'investissement https://t.co/mD8XellyGu via @Culturebox\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "En 93 déjà, 72% des femmes avait subi un acte de #harcèlement sexuel dit L. Bertalli #RTSinfrarouge #MeToo https://t.co/9yzIJgkAXD\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le mec de 50 ans au bar qui m'a dit que je mettais du rouge à lèvres uniquement pour allumer les mecs #balancetonporc\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Je me suis toujours dit, elles ont fait un #BalanceTonPorc , qu'est ce qui se serai passé si on avait fait un #BalanceTaPute ?\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ginmedaddy Dans ce cas va écrire sur #BalanceTonPorc. A moins que ton prêtre est une pouffe ce que j'en doute?  Vous les femme vous ête toutes les même, vous ne RESPECTEZ RIEN #BalanceTonPorc=Injustice faite aux femmes par les hommes #BalanceTaPouffe=Injustice faite aux hommes par les femme\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "avec #MeToo on parle de crimes : viols, agressions sexuelles etc. On parle de choses qui sont punissables par la loi (même si on sait tous-tes ce que ça donne) du coup je vois mal comment on peut parler de délation alors qu'on dénonce des pratiques punissables\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#WaltDisney - Le prince de \"La Belle au bois dormant\" est-il un prédateur sexuel ? https://t.co/jDbKD9RHJI via @franceculture #Jeunesse #Conte #Féminisme #BalanceTonPorc https://t.co/IvGS6GD1Jn\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#MeToo #metooinceste et #MeTooGay offrent aussi une opportunité de penser l’oppression que peut représenter le silence et le pouvoir de la parole (mais aussi ses limites). La parole libère mais elle n’efface pas l’irrévocable d’un acte terrible. Elle est cri de justice !\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "J'écoute #Jablonka depuis 10 min, il y a rien qui va. Le mec il n'a pas dû lire un seul truc écrit par des féministes depuis #metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Accusé d'harcèlement sexuel, le maire de Copenhague démissionne en pleine nouvelle vague de #Metoo au Danemark https://t.co/ZPYKZXneHs via @rtbfinfo\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc un nouveau hashtag à la #agressionnondenoncee\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "le nombre de #Iwas ca me brise le coeur\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@GG_RMC @DICKENSDAVID1 et la peur ? tu connais ? elle a peut être trouvé le courage de dénoncer en voyant le mouvement actuel #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Ceci EST une agression sexuelle.  Aucun débat. #balancetonporc https://t.co/NYJl1aguRV\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc j'ai été violé par le chien de Michel Drucker\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Baisse des crédits du programme 137. Annonces du Grenelle non financées. Manque de moyens des associations malgré la hausse de leur activité consécutive à #metoo. La vérité sur les #bullshit du gouvernement, dans le rapport de la très rigoureuse commission des finances du Senat! https://t.co/hTxKV5olvF :QT: La commission des finances du Sénat assez sèche sur \"le milliard d'euros\" pour l'égalité femmes hommes https://t.co/VK7nBOt2BZ https://t.co/p9Bv5jiX5A\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "En France on as vraiment un probléme.On est complétement passer à coté du mouvement #MeToo et on as donné le césar à Roman Polanski. Et là on est sur le point de passer à coté, de ce mouvement historique de justice contre le racisme. Je comprends vraiment plus rien à ce pays.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Après #MeToo / #BalanceTonPorc autour de #BalanceTonYoutubeur qui fait exploser #twitter ! Encore une fois faut prendre du recule pour ne pas faire les mêmes erreurs qui ont déjà été commise. #Squeezie :QT: Les YouTubers (y compris ceux qui crient sur tous les toits qu’ils sont féministes) qui profitent de la vulnérabili… https://t.co/B7VGErsR2z\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ATrapenard @Giulia_Fois_ @fabricearfi @marineturchi  Merci de RT🙏 La #pédocriminalité est un fléau avec desconséquences colossales sur la vie des #victimes. Besoin de #politiques publiques à la hauteur. #Iwas #StopPrescription St⛔️p #ViolencesSexuelles https://t.co/MtGmQlr7T1\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Waw ces anecdotes gravissimes sur ce HT #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le secret d'une vie bien menée c'est qu'elle soit bien remplie. #denoncetonporc #denoncetatruie #balancetonporc #Metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "\"Je me suis vraiment sentie salie\" : paroles d'éditrices à propos des violences sexistes et sexuelles dans le milieu littéraire https://t.co/717XebvMbp via @franceinfo #sexisme #féminisme #ViolenceMasculine #metoo #BalanceTonPorc\n",
      "\n",
      "Label pour le tweet suivant :\n",
      "#metoo #metooinceste #CONSISTENCY  UN JEU DIFFÉRENCE COULEUR/TEXTE  https://t.co/hA0D41vxZz\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "@ericrevel1 Et en cette période #metoo, un tel obsédé aurait pris cher. Toutes les qualités ce mec.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc alors au lieu de demander des noms, rendez-vous compte du nombre de témoignages, de l'horreur quotidienne que c'est.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Indescencence: croire que ne pas être agresseur mérite d'être célébré...  #balancetonporc https://t.co/vHsE3rYsx2\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@s_cluzel @N_Hulot Bravo! Encore une fois, notre gouvernement marque sa bonne marche dans la gestion des affaires publiques et de la séparation des pouvoirs. #mercipourcemoment #BalanceTonPorc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ellensalvi En somme #metoo a raison quand ses accusateurs (trices) accusent. Et #metoo a raison quand ses acusateurs publics (trices/ques) sont demasqué(e)s. Quoi qu’il arrive, #metoo a raison.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "https://t.co/Ee9Dpul3ph Des méthodes vraiment pré #MeToo pour acquitter les flics accusés du #violDu36 : fouiller dans la vie de la victime pour la dénigrer, l'accuser d'être ivre, l'accuser de confusion (stress post-trauma). Le #patriarcat a la vie dure, surtout dans la justice.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@CBouanchaud Quelqu’un pour m’expliquer pourquoi il y a toujours un moment de représentation hypersexualisée ? Avec #metoo, la parole et une réflexion en profondeur sur les actes er la société semblaient prendre le dessus, mais on revient à des demonstration sexualisée. Pige pas.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Les valeurs 2 @Zemmour ce n'est pas celles de notre république mais bien celles du fais ce que je dis mais pas ce que je fais Coucher avec son conseillère qui est sa subordonnée n'est pas républicain  #MeTooPolitique #balancetonporc Pensée à sa femme victime du grand remplacement :QT: #Mohamed VS #Zemmour   ➡️ Plus d’un million de vues sur mon compte #TikTok (https://t.co/huGJi7dGp4).   Merci ! https://t.co/8JYA7SB9Uo\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Super doc post #metoo en préparation pour LCP, suivez le compte sur insta ! (Et pi c'est une copine)  https://t.co/QVxkB0zReI\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "labeliser_tweet(df, nb_tweets=50, random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jAyzaJ5875dw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "mRUK1kmZ7_z8",
    "outputId": "78d2f214-ea47-47f1-d388-9679b8d6d384",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2.0    828\n",
       "1.0    270\n",
       "3.0    113\n",
       "0.0     42\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = df_label.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hnt-ro2_WpXz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 10\n",
    "MAX_LEN = 300\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-JvbX630WUHn",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89b418bcc7a451bafbe2cd902834364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e772c93523cb48b8a869f49574739852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f574914b8f4115a1a855f739e921d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=4)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=10e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "cQS2l-oQZwmL",
    "outputId": "ab347867-6f13-41ee-9457-1ea3ef877c2f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "text = df_label['text'].to_list()\n",
    "labels = df_label['label'].to_list()\n",
    "\n",
    "#user tokenizer to convert sentences into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Ge4RCSKcZztV",
    "outputId": "47bd58fd-bb54-45c5-b011-e4af769fcee9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.4, stratify = labels)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "pbFcqTLYWnIZ",
    "outputId": "ca5a0099-dba7-4b4e-ad98-14b46dbb3819",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2618875404198964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [11:58<1:47:46, 718.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 1.0668712556362152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [26:31<1:47:53, 809.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 0.957703024148941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 3/10 [41:12<1:38:15, 842.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 0.8441829631725947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 4/10 [56:13<1:26:33, 865.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7936197916666666\n",
      "Train loss: 0.7229040463765463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 5/10 [1:11:12<1:13:06, 877.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7316261574074074\n",
      "Train loss: 0.6163275490204493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 6/10 [1:25:21<57:51, 867.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7779947916666666\n",
      "Train loss: 0.5189388146003088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 7/10 [1:38:30<42:06, 842.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8236400462962963\n",
      "Train loss: 0.4161665042241414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 8/10 [1:46:59<24:32, 736.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8298611111111112\n",
      "Train loss: 0.3496982256571452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 9/10 [1:54:01<10:37, 637.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8383969907407407\n",
      "Train loss: 0.2971478613714377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [2:00:39<00:00, 723.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8423032407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_set=[]\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels.long())\n",
    "        loss = outputs[0]\n",
    "        train_loss_set.append(loss.item())    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs =  model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels.long())\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    # mettre le modèle en mode d'évaluation\n",
    "    model.eval()\n",
    "    \n",
    "    # stocker les prédictions de tous les batchs dans une liste\n",
    "    predictions = []\n",
    "    \n",
    "    # boucle sur les batches dans le dataloader de test\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        # déplacer les données sur le même dispositif que le modèle\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # désactiver le calcul des gradients pour économiser de la mémoire et accélérer les calculs\n",
    "        with torch.no_grad():\n",
    "            # faire passer les données à travers le modèle pour obtenir les logits\n",
    "            outputs =  model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            logits = outputs[0]\n",
    "    \n",
    "        # appliquer la fonction softmax pour obtenir les probabilités pour chaque classe\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # convertir les probabilités en prédictions en prenant l'indice de la classe avec la probabilité la plus élevée\n",
    "        batch_preds = torch.argmax(probs, dim=1)\n",
    "        \n",
    "        # ajouter les prédictions pour ce batch à la liste de prédictions globale\n",
    "        predictions.extend(batch_preds.cpu().numpy().tolist())\n",
    "    \n",
    "    # retourner la liste de prédictions globale\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions_val \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 18\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# désactiver le calcul des gradients pour économiser de la mémoire et accélérer les calculs\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# faire passer les données à travers le modèle pour obtenir les logits\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# appliquer la fonction softmax pour obtenir les probabilités pour chaque classe\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:1084\u001b[0m, in \u001b[0;36mCamembertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1084\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1096\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:904\u001b[0m, in \u001b[0;36mCamembertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    895\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    897\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    898\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    899\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    903\u001b[0m )\n\u001b[0;32m--> 904\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    917\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:541\u001b[0m, in \u001b[0;36mCamembertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    532\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    533\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    534\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    539\u001b[0m     )\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 541\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:467\u001b[0m, in \u001b[0;36mCamembertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    464\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    465\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 467\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:479\u001b[0m, in \u001b[0;36mCamembertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 479\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:377\u001b[0m, in \u001b[0;36mCamembertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 377\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions_val = predict(model, validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 17, 1.0: 100, 2.0: 343, 3.0: 42}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(validation_labels.numpy(), return_counts=True)\n",
    "label_counts = dict(zip(unique, counts))\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(validation_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['Autre','Presse','Opinion','Témoignage'], \n",
    "                     columns = ['Autre','Presse','Opinion','Témoignage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True, cbar = False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
