{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "kV9SWKZSWAh0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "#from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "pADt5CykCKaz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labeliser_tweet(df, nb_tweets=5, random_state=0):\n",
    "    \n",
    "    # V√©rifier si le fichier \"label.csv\" existe et charger les tweet_id d√©j√† labelis√©s\n",
    "    tweets_labelises = set()\n",
    "    try:\n",
    "        with open('label.csv', mode='r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                tweets_labelises.add(row['tweet_id'])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    # S√©lectionner un √©chantillon al√©atoire de tweets non encore labelis√©s\n",
    "    df_a_labeliser = df[~df.index.isin(tweets_labelises)].sample(n=nb_tweets, random_state=random_state)\n",
    "    \n",
    "    # Labeliser les tweets s√©lectionn√©s et enregistrer les labels dans un fichier CSV\n",
    "    with open('label.csv', mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if f.tell() == 0:\n",
    "            writer.writerow(['tweet_id', 'text', 'label'])\n",
    "        for tweet_id, text in df_a_labeliser['text'].items():\n",
    "            label = input(f'Label pour le tweet suivant :\\n{text}\\n')\n",
    "            # √âcrire les donn√©es labelis√©es dans le fichier CSV\n",
    "            writer.writerow([tweet_id, text, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "fGUP7YlcanuW",
    "outputId": "9d6da307-a96e-45dc-ca7f-acd015856f90",
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/data_concat_clean/base_annotation_fev23.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/data_concat_clean/base_annotation_fev23.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweet_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_concat_clean/base_annotation_fev23.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/data_concat_clean/base_annotation_fev23.csv', index_col='tweet_id').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKjOXzht-kvr",
    "outputId": "18bd519c-92df-4ce6-c15c-ec4555f02a8c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label pour le tweet suivant :\n",
      "Affaire #Ad√®leHaenel : le r√©alisateur #ChristopheRuggia plac√© en garde √† vue #MeToo https://t.co/6daXmWhTqK\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Un pain au chocolat peut-il permettre de se faire pardonner une agression sexuelle? #Haziza #balancetonporc https://t.co/g8YGxBzeJM\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@CordaniOfficiel Comme je vous comprends....j'ai le m√™me probl√®me avec le mois de f√©vrier....courage #MeToo #MeTooInceste #metoosuisse #suisse #inceste #silence #maltraitance\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Publication livre : \"Ni pantins ni soumis\" ou les exc√®s du #METOO  https://t.co/B0YvW5GyXA @libgallimard https://t.co/PcE29MWuPs\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "*‚í∏‚í∏‚û• #Venezuela ‚òõ Communist psychopaths | https://t.co/iFKJd7x2Kb | #Residente #Ren√©P√©rez #UnicefComunista #Unicef #JairBolsonaro #FernandoAlb√°n #Brasil #BrieLarson #BenicioDelToro #MeToo #AngelinaJolie #ACNUR #CateBlanchett #LGBT #Comunismo #Anticomunismo https://t.co/XmQppraaNU\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "@briefmenews en effet, vs avez raison. Tant mieux, √ßa me permet de continuer √† vs lire avec confiance. Suoer r√©cap sur l'Alg√©rie ds le dernier Brief. Je compte sur vs pr faire un aussi bon brief sur #MeToo et #IDidntReport\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Un budget qui va titiller le scrotum des fran√ßais, sans les toucher, normal √ßa fait bien longtemps qu'ils n'en n'ont plus ! #metoo https://t.co/PUFgeryO88\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Il y a des ≈ìuvres qui au del√† de leurs beaut√©s ont une force cathartique societale po√©tique indispensable Merci @AndreaBescond  #ericmetayer  la reconstruction est possible #metoo #JeSuisVictime #psychanalyse #stopviolencesfaitesauxenfants #imprescriptibilit√© https://t.co/RCedpIqc3O :QT: En 2016, un ovni d√©barquait au Petit @TMontparnasse. Ovationn√© chaque soir par un public boulevers√©.  Couronn√© par le Moli√®re du seul/e en sc√®ne, #LESCHATOUILLES d‚Äô@AndreaBescond, mise en sc√®ne @Metayereric, est exceptionnellement en ligne jusqu‚Äôau 3/05 !  https://t.co/vriKkmkAZI\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#metoo Alors pour 16 -18, en ce moment precis, (3:07 le 25/07/202i) je ne sait pas les appeler. Je suis nul en orthographe et fort en grammaire quand j'√©tais √† l '√©cole primaire. je ne sais pas pourquoi je dis cela.\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "VIDEO TPMP People : vifs √©changes sur le plateau autour du mouvement #MeToo https://t.co/XT1pzDczgG https://t.co/JFOpEcFB7A\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc : on d√©mon les porcs sans d√©noncer la porcherie #RTLMatin @MadeJessey #SensCommun #LR\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@MarleneSchiappa @EPhilippePM @NadiaHAI78 @MarleneSchiappa  Quand allez-vous porter secours aux enseignantes violent√©es par leur  chef d'√©tablissement et aux lanceurs d'alerte  r√©prim√©s par @EducationFrance @justice_gouv ?   Merci de cesser de conforter l'Omerta.   #metoo #PasdeVague #NousToutes   https://t.co/LXngHxIYrA\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Absolution accord√©e √† un agresseur sexuel : le DPCP fera appel https://t.co/pTxhlpwpjS #Qu√©bec #polqc #simonhoule #TroisRivieres #AgressionNonDenoncee #MeToo #JusticeQc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "The Les concern√©s Daily est en ligne! https://t.co/57GQC6LQR8 #afp #metoo\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@Frambwazz @doucefrance13 @MonsieurAbdool La diff√©rence c'est que le BalanceTonYoutubeur c'est que le youtubeur il se sert de sa notori√©t√© et de la faiblesse psychologique de ses fans. Un random c'est dans #BalanceTonPorc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Sarah Palin Compares Sacha Baron Cohen Duping Politicians to #MeToo https://t.co/GuJdeW4Ohr https://t.co/DjVxDR68uK\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "Le gouvernement est aveugle aux aspirations de la jeune g√©n√©ration #MeToo, par Les invit√©s de Mediapart via @MediapartBlogs https://t.co/95htIrxLHZ\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "@tweekette75 @MaitreKlem @HutzLionel1 @Brujulasegunda @Le___Doc @immaterielle @sui_gene_ris @Kdet_Rousselle Je ne pense pas avoir √©crit √† un seul moment LES Gyneco dans leur ensemble. LA profession de Gyneco. Je visais ce monsieur et ces comparses.  mais r√©pondre #NotAllGyneco quand on parle probl√®mes IVG et violences Gyneco est pour moi du m√™me niveau que #NotAllMen contre #MeToo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#MeToo : le studio Weinstein vendu √† une soci√©t√© d'investissement https://t.co/mD8XellyGu via @Culturebox\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "En 93 d√©j√†, 72% des femmes avait subi un acte de #harc√®lement sexuel dit L. Bertalli #RTSinfrarouge #MeToo https://t.co/9yzIJgkAXD\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le mec de 50 ans au bar qui m'a dit que je mettais du rouge √† l√®vres uniquement pour allumer les mecs #balancetonporc\n",
      "3\n",
      "Label pour le tweet suivant :\n",
      "Je me suis toujours dit, elles ont fait un #BalanceTonPorc , qu'est ce qui se serai pass√© si on avait fait un #BalanceTaPute ?\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ginmedaddy Dans ce cas va √©crire sur #BalanceTonPorc. A moins que ton pr√™tre est une pouffe ce que j'en doute?  Vous les femme vous √™te toutes les m√™me, vous ne RESPECTEZ RIEN #BalanceTonPorc=Injustice faite aux femmes par les hommes #BalanceTaPouffe=Injustice faite aux hommes par les femme\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "avec #MeToo on parle de crimes : viols, agressions sexuelles etc. On parle de choses qui sont punissables par la loi (m√™me si on sait tous-tes ce que √ßa donne) du coup je vois mal comment on peut parler de d√©lation alors qu'on d√©nonce des pratiques punissables\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#WaltDisney - Le prince de \"La Belle au bois dormant\" est-il un pr√©dateur sexuel ? https://t.co/jDbKD9RHJI via @franceculture #Jeunesse #Conte #F√©minisme #BalanceTonPorc https://t.co/IvGS6GD1Jn\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#MeToo #metooinceste et #MeTooGay offrent aussi une opportunit√© de penser l‚Äôoppression que peut repr√©senter le silence et le pouvoir de la parole (mais aussi ses limites). La parole lib√®re mais elle n‚Äôefface pas l‚Äôirr√©vocable d‚Äôun acte terrible. Elle est cri de justice !\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "J'√©coute #Jablonka depuis 10 min, il y a rien qui va. Le mec il n'a pas d√ª lire un seul truc √©crit par des f√©ministes depuis #metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Accus√© d'harc√®lement sexuel, le maire de Copenhague d√©missionne en pleine nouvelle vague de #Metoo au Danemark https://t.co/ZPYKZXneHs via @rtbfinfo\n",
      "1\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc un nouveau hashtag √† la #agressionnondenoncee\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "le nombre de #Iwas ca me brise le coeur\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@GG_RMC @DICKENSDAVID1 et la peur ? tu connais ? elle a peut √™tre trouv√© le courage de d√©noncer en voyant le mouvement actuel #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Ceci EST une agression sexuelle.  Aucun d√©bat. #balancetonporc https://t.co/NYJl1aguRV\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc j'ai √©t√© viol√© par le chien de Michel Drucker\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Baisse des cr√©dits du programme 137. Annonces du Grenelle non financ√©es. Manque de moyens des associations malgr√© la hausse de leur activit√© cons√©cutive √† #metoo. La v√©rit√© sur les #bullshit du gouvernement, dans le rapport de la tr√®s rigoureuse commission des finances du Senat! https://t.co/hTxKV5olvF :QT: La commission des finances du S√©nat assez s√®che sur \"le milliard d'euros\" pour l'√©galit√© femmes hommes https://t.co/VK7nBOt2BZ https://t.co/p9Bv5jiX5A\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "En France on as vraiment un probl√©me.On est compl√©tement passer √† cot√© du mouvement #MeToo et on as donn√© le c√©sar √† Roman Polanski. Et l√† on est sur le point de passer √† cot√©, de ce mouvement historique de justice contre le racisme. Je comprends vraiment plus rien √† ce pays.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Apr√®s #MeToo / #BalanceTonPorc autour de #BalanceTonYoutubeur qui fait exploser #twitter ! Encore une fois faut prendre du recule pour ne pas faire les m√™mes erreurs qui ont d√©j√† √©t√© commise. #Squeezie :QT: Les YouTubers (y compris ceux qui crient sur tous les toits qu‚Äôils sont f√©ministes) qui profitent de la vuln√©rabili‚Ä¶ https://t.co/B7VGErsR2z\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ATrapenard @Giulia_Fois_ @fabricearfi @marineturchi  Merci de RTüôè La #p√©docriminalit√© est un fl√©au avec descons√©quences colossales sur la vie des #victimes. Besoin de #politiques publiques √† la hauteur. #Iwas #StopPrescription St‚õîÔ∏èp #ViolencesSexuelles https://t.co/MtGmQlr7T1\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Waw ces anecdotes gravissimes sur ce HT #balancetonporc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Le secret d'une vie bien men√©e c'est qu'elle soit bien remplie. #denoncetonporc #denoncetatruie #balancetonporc #Metoo\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "\"Je me suis vraiment sentie salie\" : paroles d'√©ditrices √† propos des violences sexistes et sexuelles dans le milieu litt√©raire https://t.co/717XebvMbp via @franceinfo #sexisme #f√©minisme #ViolenceMasculine #metoo #BalanceTonPorc\n",
      "\n",
      "Label pour le tweet suivant :\n",
      "#metoo #metooinceste #CONSISTENCY  UN JEU DIFF√âRENCE COULEUR/TEXTE  https://t.co/hA0D41vxZz\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "@ericrevel1 Et en cette p√©riode #metoo, un tel obs√©d√© aurait pris cher. Toutes les qualit√©s ce mec.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "#balancetonporc alors au lieu de demander des noms, rendez-vous compte du nombre de t√©moignages, de l'horreur quotidienne que c'est.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Indescencence: croire que ne pas √™tre agresseur m√©rite d'√™tre c√©l√©br√©...  #balancetonporc https://t.co/vHsE3rYsx2\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@s_cluzel @N_Hulot Bravo! Encore une fois, notre gouvernement marque sa bonne marche dans la gestion des affaires publiques et de la s√©paration des pouvoirs. #mercipourcemoment #BalanceTonPorc\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@ellensalvi En somme #metoo a raison quand ses accusateurs (trices) accusent. Et #metoo a raison quand ses acusateurs publics (trices/ques) sont demasqu√©(e)s. Quoi qu‚Äôil arrive, #metoo a raison.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "https://t.co/Ee9Dpul3ph Des m√©thodes vraiment pr√© #MeToo pour acquitter les flics accus√©s du #violDu36 : fouiller dans la vie de la victime pour la d√©nigrer, l'accuser d'√™tre ivre, l'accuser de confusion (stress post-trauma). Le #patriarcat a la vie dure, surtout dans la justice.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "@CBouanchaud Quelqu‚Äôun pour m‚Äôexpliquer pourquoi il y a toujours un moment de repr√©sentation hypersexualis√©e ? Avec #metoo, la parole et une r√©flexion en profondeur sur les actes er la soci√©t√© semblaient prendre le dessus, mais on revient √† des demonstration sexualis√©e. Pige pas.\n",
      "2\n",
      "Label pour le tweet suivant :\n",
      "Les valeurs 2 @Zemmour ce n'est pas celles de notre r√©publique mais bien celles du fais ce que je dis mais pas ce que je fais Coucher avec son conseill√®re qui est sa subordonn√©e n'est pas r√©publicain  #MeTooPolitique #balancetonporc Pens√©e √† sa femme victime du grand remplacement :QT: #Mohamed VS #Zemmour   ‚û°Ô∏è Plus d‚Äôun million de vues sur mon compte #TikTok (https://t.co/huGJi7dGp4).   Merci ! https://t.co/8JYA7SB9Uo\n",
      "0\n",
      "Label pour le tweet suivant :\n",
      "Super doc post #metoo en pr√©paration pour LCP, suivez le compte sur insta ! (Et pi c'est une copine)  https://t.co/QVxkB0zReI\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "labeliser_tweet(df, nb_tweets=50, random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jAyzaJ5875dw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "mRUK1kmZ7_z8",
    "outputId": "78d2f214-ea47-47f1-d388-9679b8d6d384",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2.0    828\n",
       "1.0    270\n",
       "3.0    113\n",
       "0.0     42\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label = df_label.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hnt-ro2_WpXz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 10\n",
    "MAX_LEN = 300\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-JvbX630WUHn",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89b418bcc7a451bafbe2cd902834364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)tencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e772c93523cb48b8a869f49574739852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f574914b8f4115a1a855f739e921d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=4)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=10e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "cQS2l-oQZwmL",
    "outputId": "ab347867-6f13-41ee-9457-1ea3ef877c2f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "text = df_label['text'].to_list()\n",
    "labels = df_label['label'].to_list()\n",
    "\n",
    "#user tokenizer to convert sentences into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Ge4RCSKcZztV",
    "outputId": "47bd58fd-bb54-45c5-b011-e4af769fcee9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.4, stratify = labels)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "pbFcqTLYWnIZ",
    "outputId": "ca5a0099-dba7-4b4e-ad98-14b46dbb3819",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2618875404198964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|‚ñà         | 1/10 [11:58<1:47:46, 718.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 1.0668712556362152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|‚ñà‚ñà        | 2/10 [26:31<1:47:53, 809.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 0.957703024148941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|‚ñà‚ñà‚ñà       | 3/10 [41:12<1:38:15, 842.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.683666087962963\n",
      "Train loss: 0.8441829631725947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [56:13<1:26:33, 865.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7936197916666666\n",
      "Train loss: 0.7229040463765463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [1:11:12<1:13:06, 877.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7316261574074074\n",
      "Train loss: 0.6163275490204493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [1:25:21<57:51, 867.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7779947916666666\n",
      "Train loss: 0.5189388146003088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [1:38:30<42:06, 842.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8236400462962963\n",
      "Train loss: 0.4161665042241414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [1:46:59<24:32, 736.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8298611111111112\n",
      "Train loss: 0.3496982256571452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [1:54:01<10:37, 637.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8383969907407407\n",
      "Train loss: 0.2971478613714377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [2:00:39<00:00, 723.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8423032407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_set=[]\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels.long())\n",
    "        loss = outputs[0]\n",
    "        train_loss_set.append(loss.item())    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs =  model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels.long())\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    # mettre le mod√®le en mode d'√©valuation\n",
    "    model.eval()\n",
    "    \n",
    "    # stocker les pr√©dictions de tous les batchs dans une liste\n",
    "    predictions = []\n",
    "    \n",
    "    # boucle sur les batches dans le dataloader de test\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        # d√©placer les donn√©es sur le m√™me dispositif que le mod√®le\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # d√©sactiver le calcul des gradients pour √©conomiser de la m√©moire et acc√©l√©rer les calculs\n",
    "        with torch.no_grad():\n",
    "            # faire passer les donn√©es √† travers le mod√®le pour obtenir les logits\n",
    "            outputs =  model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            logits = outputs[0]\n",
    "    \n",
    "        # appliquer la fonction softmax pour obtenir les probabilit√©s pour chaque classe\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # convertir les probabilit√©s en pr√©dictions en prenant l'indice de la classe avec la probabilit√© la plus √©lev√©e\n",
    "        batch_preds = torch.argmax(probs, dim=1)\n",
    "        \n",
    "        # ajouter les pr√©dictions pour ce batch √† la liste de pr√©dictions globale\n",
    "        predictions.extend(batch_preds.cpu().numpy().tolist())\n",
    "    \n",
    "    # retourner la liste de pr√©dictions globale\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions_val \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 18\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# d√©sactiver le calcul des gradients pour √©conomiser de la m√©moire et acc√©l√©rer les calculs\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# faire passer les donn√©es √† travers le mod√®le pour obtenir les logits\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# appliquer la fonction softmax pour obtenir les probabilit√©s pour chaque classe\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:1084\u001b[0m, in \u001b[0;36mCamembertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1084\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1096\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:904\u001b[0m, in \u001b[0;36mCamembertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    895\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    897\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    898\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    899\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    903\u001b[0m )\n\u001b[0;32m--> 904\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    917\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:541\u001b[0m, in \u001b[0;36mCamembertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    532\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    533\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    534\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    539\u001b[0m     )\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 541\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:467\u001b[0m, in \u001b[0;36mCamembertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    464\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    465\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 467\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:479\u001b[0m, in \u001b[0;36mCamembertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 479\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:377\u001b[0m, in \u001b[0;36mCamembertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 377\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions_val = predict(model, validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 17, 1.0: 100, 2.0: 343, 3.0: 42}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(validation_labels.numpy(), return_counts=True)\n",
    "label_counts = dict(zip(unique, counts))\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(validation_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['Autre','Presse','Opinion','T√©moignage'], \n",
    "                     columns = ['Autre','Presse','Opinion','T√©moignage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True, cbar = False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
